---
layout: glossary
title: "Token"
---

## Definition
A smaller unit of text (word, part of word, or punctuation) that AI models use to understand and generate language.
